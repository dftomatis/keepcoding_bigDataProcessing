# ğŸ§  PrÃ¡ctica con Apache Spark + Scala

Este proyecto contiene una serie de ejercicios resueltos con **Apache Spark usando Scala**, enfocados en:

- Operaciones bÃ¡sicas con DataFrames y RDDs
- Funciones definidas por el usuario (UDF)
- Joins y agregaciones
- Lectura de archivos CSV
- Escritura y validaciÃ³n de tests con **ScalaTest**

---

## ğŸ—‚ Estructura del proyecto

```
src/
â”œâ”€â”€ main/
â”‚   â””â”€â”€ scala/
â”‚       â””â”€â”€ practica/
â”‚           â””â”€â”€ practica.scala   <-- ImplementaciÃ³n de los ejercicios (objeto `practica`)
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ resources/
â”‚   â”‚   â””â”€â”€ ventas.csv           <-- Archivo CSV usado en el ejercicio 5
â”‚   â””â”€â”€ scala/
â”‚       â””â”€â”€ practica/
â”‚           â””â”€â”€ practicaTest.scala   <-- Tests de todos los ejercicios
â”‚       â””â”€â”€ utils/
â”‚           â””â”€â”€ TestInit.scala       <-- InicializaciÃ³n del entorno de test (SparkSession)
```

---

## ğŸš€ Requisitos

| Componente    | VersiÃ³n mÃ­nima recomendada |
|---------------|----------------------------|
| Scala         | 2.12.x                     |
| Apache Spark  | 3.4.0                      |
| sbt           | 1.5+                       |
| Java JDK      | 11 o 17                    |
| ScalaTest     | 3.2.x                      |

---

## âš™ï¸ Dependencias sugeridas (build.sbt)

Asegurate de tener algo similar en tu `build.sbt`:

```scala
scalaVersion := "2.12.18"

libraryDependencies ++= Seq(
  "org.apache.spark" %% "spark-core" % "3.4.0" % "provided",
  "org.apache.spark" %% "spark-sql" % "3.4.0" % "provided",
  "org.scalatest" %% "scalatest" % "3.2.18" % "test"
)
```

> ğŸ” Si usÃ¡s IntelliJ, recordÃ¡ activar el plugin de **Scala** y sincronizar el proyecto SBT.

---

## ğŸ§ª Ejecutar los tests

Desde la terminal, ubicado en la raÃ­z del proyecto:

```bash
sbt test
```

O, desde IntelliJ:

1. Clic derecho sobre la clase `practicaTest.scala`
2. Seleccionar: `Run 'practicaTest'`

---

## ğŸ“ Detalle de ejercicios

1. **Ejercicio 1**: Operaciones con DataFrames (filtro y ordenamiento por calificaciÃ³n)
2. **Ejercicio 2**: UDF para determinar si un nÃºmero es par o impar
3. **Ejercicio 3**: Join de estudiantes con calificaciones y cÃ¡lculo del promedio
4. **Ejercicio 4**: Uso de RDD para contar ocurrencias de palabras
5. **Ejercicio 5**: Lectura de un CSV y cÃ¡lculo del ingreso total por producto

---

## ğŸ“ Archivo CSV de prueba

El archivo `ventas.csv` se encuentra en:

```
src/test/resources/ventas.csv
```

> âš ï¸ Es importante no moverlo ni renombrarlo, ya que los tests acceden a Ã©l dinÃ¡micamente mediante `getClass.getResource(...)`.

---

## âœ… Autor

Desarrollado por **Ing. Dario Tomatis** como parte de prÃ¡cticas con Spark y Scala.

---
